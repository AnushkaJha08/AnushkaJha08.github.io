{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6c3ac0-2e70-4cb5-b1db-51386bbffd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import hashlib\n",
    "import json\n",
    "import librosa  # For loading audio files\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc587bd-aec8-470d-b971-7cfcc43ad981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\Minorproject_Multimodal\\Lib\\site-packages\\transformers\\configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2Model: ['project_hid.weight', 'quantizer.weight_proj.bias', 'project_q.weight', 'project_hid.bias', 'project_q.bias', 'quantizer.weight_proj.weight', 'quantizer.codevectors']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0438052-7ab0-45c1-847d-277b412f01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = os.path.join('input', 'audio')\n",
    "os.makedirs(audio_dir, exist_ok=True)  # Create directory if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb77abe-a239-48fa-9e7d-1536c27f5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'database/multimodal_rag.db'\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8391b6-00d3-4707-b291-bba3c17128bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio already processed: bird-sound-249237.mp3\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(audio_dir):\n",
    "    if filename.lower().endswith('.mp3'):  # Process MP3 files only\n",
    "        audio_path = os.path.join(audio_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Generate content hash to avoid duplicates\n",
    "            with open(audio_path, \"rb\") as f:\n",
    "                content_hash = hashlib.sha256(f.read()).hexdigest()\n",
    "            \n",
    "            # Check if audio already exists in database\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('SELECT id FROM embeddings WHERE content_hash = ?', (content_hash,))\n",
    "            if cursor.fetchone():\n",
    "                print(f\"Audio already processed: {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # Load and process MP3 file (convert MP3 to waveform)\n",
    "            waveform, sr = librosa.load(audio_path, sr=16000)  # Resample to 16kHz\n",
    "            inputs = processor(waveform, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "            with torch.no_grad():\n",
    "                embedding = model(**inputs).last_hidden_state.mean(dim=1).numpy()\n",
    "            \n",
    "            \n",
    "            # Insert into database with metadata\n",
    "            conn.execute('''\n",
    "                INSERT INTO embeddings (modality, content_hash, embedding, metadata)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "            ''', ('audio', content_hash, embedding.tobytes(), json.dumps({\n",
    "                \"filename\": filename,\n",
    "                \"path\": audio_path,\n",
    "                \"duration\": librosa.get_duration(y=waveform, sr=sr)\n",
    "            })))\n",
    "            \n",
    "            print(f\"Processed and stored: {filename}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66566bb-4df6-47b0-ab18-b427839f120e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio processing complete!\n"
     ]
    }
   ],
   "source": [
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Audio processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d1fd3-aa21-42f6-ab70-a372fef6d7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
